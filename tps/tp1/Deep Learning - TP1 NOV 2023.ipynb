{"cells":[{"cell_type":"markdown","metadata":{"id":"ftXnmgdtOuZs"},"source":["# Universidad de Buenos Aires\n","# Deep Learning - TP1\n","# Noviembre 2023\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aEx1gM2sG4OP"},"source":["El TP comienza al momento de recibir este correo y la ventana de entrega estará abierta hasta el Domingo 24 de diciembre. La resolución es individual. Pueden utilizar los contenidos vistos en clase y otra bibliografía. Si se toman ideas de fuentes externas deben ser correctamente citas incluyendo el correspondiente link o página de libro.\n","\n","El formato de entrega debe ser un “link a un colab” (compartir a las siguientes direcciones: maxit1992@gmail.com y lelectronfou@gmail.com). Tanto los resultados, como el código y las explicaciones deben quedar guardados y visualizables en el colab."]},{"cell_type":"markdown","metadata":{"id":"nlfSxrehmuYW"},"source":["## Ejercicio 1\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FY2z-GSXoFvq"},"source":["Se quiere encontrar el máximo de la siguiente función:\n","\n","$z = -(x - 2)^2 - (y - 3)^2 + 4$\n","<br>\n","<br>\n","1. Aplicar gradiente de forma analítica e igualar a zero para encontrar los valores de $x$ e $y$ donde $z$ tiene un máximo. Cuál es el valor del máximo?\n","\n","2. Aplicar SGD para encontrar la ubicación del máximo de manera numérica (pueden utilizar pytorch). Comparar con el resultado obtenido en el punto 1"]},{"cell_type":"markdown","metadata":{"id":"WL2PjUnT_Uvk"},"source":["## Ejercicio 2"]},{"cell_type":"markdown","metadata":{"id":"73yqE_Sslwif"},"source":["\n","Descargar el dataset del siguiente link: https://drive.google.com/file/d/1eFWn7eDmSFUK1JuuBBykxkC9J0CGYDKe/view?usp=sharing.\n","\n","El dataset contiene mediciones obtenidas al ensayar un sistema de posicionamiento. El sistema consiste en un dispositivo móvil del cual se desea conocer la posición y 13 \"balizas\" fijas (distribuidas en un salón) que emiten señales de radio.\n","\n","Cada fila del dataset contiene una posición del dispositivo móvil y los niveles de señal recibida (de las señales emitidas por cada una de las 13 balizas fijas) en dicha posición.\n","\n","![Salon](https://drive.google.com/uc?export=view&id=1z3uHEd3tS1kQpGXfhPYn2GFfA95v_ArW)\n","\n","\n","Algunas consideraciones:\n","- La imágen anterior es orientativa, no se encuentra a escala ni representa la verdadera posición de las balizas fijas.\n","- La posición en el salón se divide en una cuadrícula. La posición horizontal se codifica con una letra de la A a la Z y la posición vertical se codifica con valores de 01 a 20.\n","- El nivel de señal recibida se mide de 0 (máximo teórico) a -200 (mínimo teórico). NA significa que no se recibe señal de la baliza en dicha posición. A efectos prácticos no recibir señal (NA) es equivalente a recibir una señal con nivel -200.\n","\n","**Consignas:**\n","\n","1. Analizar el dataset y aplicar las transformaciones que considere necesarias para entrenar un modelo de red neuronal.\n","\n","2. Entrenar un modelo de **Deep Learning** con múltiples capas lineales que prediga la posición del dispositivo móvil en el salón (vertical y horizontal) a partir de las mediciones de los niveles de las 13 balizas. Graficar la evolución de la función de pérdida y la evolución de la métrica [MAE](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html) durante el entrenamiento.\n","\n","3. Comprobar el funcionamiento del modelo realizando una predicción sobre una muestra aleatoria del dataset y comparar con la posición real.\n","\n","Con la finalidad de ahorrar energía en el dispositivo móvil y simplificar el sistema, se quiere ensayar la posibilidad de predecir la posición solamente con la información del nivel de señal de las 2 balizas mas cercanas.\n","\n","4. Aplicar las transformaciones necesarias sobre el dataset para obtener un nuevo dataset que contenga solamente la información de las 2 balizas con mayor nivel de señal (ver imágen adjunta). Si no se recibe señal de una 2da baliza, proponer un método para completar la información faltante.\n","\n","![Dataset Punto 4](https://drive.google.com/uc?export=view&id=1kz1Y5m5rmbYPiuZIc4QHvnt4uFB2TwWu)\n","\n","\n","5. Entrenar un modelo de **Deep Learning** que prediga la posición del dispositivo móvil en el salón (vertical y horizontal) a partir del dataset del punto 4, incluyendo **una capa de embeddings** para ambos número (o IDs) de balizas.\n","\n","6. Comparar los resultados obtenidos con los modelo de los puntos 2 y 5 y enunciar conclusiones."]},{"cell_type":"markdown","metadata":{},"source":["# Resolucion\n","## Importacion de librerías públicas"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Importar librerías\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from numpy import random, vectorize\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from torch.utils.data import DataLoader, Dataset"]},{"cell_type":"markdown","metadata":{},"source":["## Asignar cómputo a la gráfica o a la CPU"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{},"source":["## Definición de funciones"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def process_single_coordinate(coor: str):\n","    ZERO_LETTER = ord(\"A\")\n","    x = ord(coor[0]) - ZERO_LETTER\n","    y = int(coor[1:3])\n","    return x, y\n","\n","\n","def process_coordinates(col: pd.Series):\n","    x, y = process_single_coordinate(col)\n","    return pd.Series({\"x\": x, \"y\": y})"]},{"cell_type":"markdown","metadata":{},"source":["## Ejercicio 1\n","#### Apartado 1\n","La resolución analítica es la siguiente:\n","\n","z = -(x-2)^2 -(y-3)^2 + 4 \n","\n","z = -x^2 + 4x - 4 - y^2 + 6y - 9 + 4\n","\n","z = -x^2 + 4x - y^2 + 6y -9\n","\n","\n","Realizamos el cáculo del gradiente derivando la función en `x` y en `y`:\n","\n","dz/dx = -2x + 4\n","\n","dz/dy = -2y + 6\n","\n","\n","El punto donde el gradiente es 0 es en el punto (x,y) = (2,3)"]},{"cell_type":"markdown","metadata":{},"source":["#### Apartado 2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Defino 2 tensores con seguimiento de gradiente, valor inicial arbitrario\n","x = torch.tensor([4.0], requires_grad=True)\n","y = torch.tensor([-1.0], requires_grad=True)\n","\n","# Hiperparámetros SGD\n","lr = 0.1\n","max_iter = 50\n","\n","# Resultados intermedios\n","x_values = []\n","y_values = []\n","z_values = []\n","\n","# SGD Loop\n","for epoch in range(max_iter):\n","    z = (\n","        (x - 2) ** 2 + (y - 3) ** 2 - 4\n","    )  # Buscar un máximo de z es lo mismo que buscar el mínimo de -z\n","\n","    # Guardar los valores en cada iteración\n","    x_values.append(x.item())\n","    y_values.append(y.item())\n","    z_values.append(-1 * z.item())  # El valor de z sí es el original\n","\n","    z.backward()  # Calcular gradientes\n","\n","    # Actualizar parámetros\n","    with torch.no_grad():\n","        x -= lr * x.grad\n","        y -= lr * y.grad\n","        # Reiniciar gradientes\n","        x.grad.zero_()\n","        y.grad.zero_()\n","\n","# Impresión de resultados\n","plt.figure(figsize=(12, 4))\n","\n","plt.plot(x_values, label=\"x\")\n","plt.plot(y_values, label=\"y\")\n","plt.plot(z_values, label=\"z\")\n","\n","plt.title(\"Evolución de x, y, y z en cada iteración\")\n","plt.xlabel(\"Iteración\")\n","plt.legend()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Como se puede observar, el método de gradiente actualiza los valores de las variables hasta que alcanzan el punto de gradiente 0 en el punto (2,3)\n","tal y como habíamos calculado de forma analítica"]},{"cell_type":"markdown","metadata":{},"source":["## Ejercicio 2\n","#### Apartado 1"]},{"cell_type":"markdown","metadata":{},"source":["Transformaciones aplicadas al set de datos:\n","- Convertir los datos faltantes en -200\n","- Transformar las coordenadas en x,y para la función distancia"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = pd.read_csv(\"resources/Positioning_data.csv\")\n","data = data.fillna(-200)  # Reemplazo de valores vacíos\n","data[[\"x\", \"y\"]] = data[\"Pos\"].apply(process_coordinates)\n","\n","# Preparación de datos\n","x_cols = [\n","    \"Baliza1\",\n","    \"Baliza2\",\n","    \"Baliza3\",\n","    \"Baliza4\",\n","    \"Baliza5\",\n","    \"Baliza6\",\n","    \"Baliza7\",\n","    \"Baliza8\",\n","    \"Baliza9\",\n","    \"Baliza10\",\n","    \"Baliza11\",\n","    \"Baliza12\",\n","    \"Baliza13\",\n","]\n","y_cols = [\"x\", \"y\"]\n","\n","X_e = data[x_cols].values\n","Y_e = data[y_cols].values\n","\n","print(data[y_cols+x_cols].head())"]},{"cell_type":"markdown","metadata":{},"source":["#### Apartado 2\n","Definición de la red neuronal"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class BeaconPositioningNN(nn.Module):\n","    layer_1: nn.Linear\n","    layer_2: nn.ReLU\n","    layer_3: nn.Linear\n","    layer_4: nn.ReLU\n","    layer_5: nn.Linear\n","    output: nn.LeakyReLU\n","\n","    def __init__(self):\n","        super().__init__()\n","        self.layer_1 = nn.Linear(\n","            in_features=13, out_features=78, bias=True\n","        )  # Idea for number of perceptrons in middle layers: nº of relations between 13 beacons = 13*12/2\n","        self.layer_2 = nn.ReLU()\n","        self.layer_3 = nn.Linear(in_features=78, out_features=78, bias=True)\n","        self.layer_4 = nn.ReLU()\n","        self.layer_5 = nn.Linear(in_features=78, out_features=2, bias=True)\n","        self.output = nn.LeakyReLU()\n","\n","    def forward(self, x):\n","        # Defino el cálculo del paso forward\n","        x = self.layer_1(x)\n","        x = self.layer_2(x)\n","        x = self.layer_3(x)\n","        x = self.layer_4(x)\n","        x = self.layer_5(x)\n","        x = self.output(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["Resolución"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Dividir datos en conjuntos de entrenamiento y prueba\n","X_train_e_num, X_test_e_num, Y_train_e, Y_test_e = train_test_split(\n","    X_e, Y_e, test_size=0.2, random_state=42\n",")\n","\n","# Convertir a tensores de PyTorch\n","X_train_e_num = torch.tensor(X_train_e_num, dtype=torch.float32).to(device)\n","Y_train_e = torch.tensor(Y_train_e, dtype=torch.float32).to(device)\n","X_test_e_num = torch.tensor(X_test_e_num, dtype=torch.float32).to(device)\n","Y_test_e = torch.tensor(Y_test_e, dtype=torch.float32).to(device)\n","\n","# Instanciamos la red\n","nnet_e = BeaconPositioningNN()\n","# Copio la red neuronal al dispositivo donde entrene la red neuronal\n","nnet_e = nnet_e.to(device)\n","# Mi funcion de Loss es MSE porque es simplemente la versión promediada de la distancia euclidiana al cuadrado\n","loss_function = torch.nn.MSELoss()\n","mae_function = mean_absolute_error\n","# Optimizer\n","optimizer = torch.optim.Adam(nnet_e.parameters(), lr=0.0001)\n","# cantidad de epochs\n","epochs = 1000\n","\n","# Lista para almacenar el valor medio de pérdida en cada iteración\n","train_loss_values = []\n","valid_loss_values = []\n","train_mae_values = []\n","valid_mae_values = []\n","\n","# Doble loop algoritmo Mini-Batch\n","for epoch in range(epochs):\n","    ############################################\n","    ## Entrenamiento\n","    ############################################\n","    nnet_e.train(True)\n","\n","    # Paso forward\n","    # Limpio optimizer para empezar un nuevo cálculo de gradiente\n","    optimizer.zero_grad()\n","    train_output = nnet_e(X_train_e_num)\n","\n","    # Calculo el loss y mae\n","    train_loss = loss_function(train_output, Y_train_e)\n","    train_mae = mae_function(train_output.cpu().detach(), Y_train_e.cpu().detach())\n","\n","    # Backpropagation\n","    train_loss.backward()\n","\n","    # Actualizar los parámetros\n","    optimizer.step()\n","\n","    # Calcular y almacenar el valor medio\n","    train_avg_loss = torch.mean(train_loss).item()\n","    train_loss_values.append(train_avg_loss)\n","    train_mae_values.append(train_mae)\n","\n","    ############################################\n","    ## Validación\n","    ############################################\n","    # Desactivo el cálculo de gradiente para validación\n","    nnet_e.train(False)\n","\n","    # Paso forward\n","    valid_output = nnet_e(X_test_e_num)\n","\n","    # Calculo el loss\n","    valid_loss = loss_function(valid_output, Y_test_e)\n","    valid_mae = mae_function(valid_output.cpu().detach(), Y_test_e.cpu().detach())\n","\n","    # En validación no hago backpropagation!!\n","\n","    # Calcular y almacenar el valor medio de pérdida\n","    valid_avg_loss = torch.mean(valid_loss).item()\n","    valid_loss_values.append(valid_avg_loss)\n","    valid_mae_values.append(valid_mae)\n","\n","############################################\n","## Impresión de resultados por epoch\n","############################################\n","\n","# Crear una figura con dos subgráficos (2 filas, 1 columna)\n","fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n","# Graficar\n","axes[0].plot(train_loss_values, label=\"train\")\n","axes[0].plot(valid_loss_values, label=\"validation\")\n","axes[0].set_xlabel('Iteración')\n","axes[0].set_ylabel('Loss')\n","axes[0].set_title('Loss function (MSE) evolution')\n","axes[0].legend()\n","\n","axes[1].plot(train_mae_values, label=\"train\")\n","axes[1].plot(valid_mae_values, label=\"validation\")\n","axes[1].set_xlabel('Iteración')\n","axes[1].set_ylabel('MAE')\n","axes[1].set_title('MAE evolution')\n","axes[1].legend()\n","\n","# Agregar etiquetas y título\n","fig.suptitle(\"Metricas\")\n","\n","\n","# Mostrar el gráfico\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Apartado 3"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["random_index = random.choice(len(X_e), size=5, replace=False)\n","\n","ran_x = torch.tensor(X_e[random_index], dtype=torch.float32).to(device)\n","ran_y = Y_e[random_index]\n","\n","nnet_e.train(False)\n","\n","pred_y = nnet_e(ran_x).cpu().detach()\n","\n","# Crear un gráfico de dispersión para visualizar las predicciones y los valores reales\n","plt.scatter(\n","    pred_y[:, 0],\n","    pred_y[:, 1],\n","    label=\"Predicciones\",\n","    c=range(len(pred_y)),\n","    cmap=\"cividis\",\n",")\n","plt.scatter(\n","    ran_y[:, 0],\n","    ran_y[:, 1],\n","    label=\"Valores reales\",\n","    c=range(len(ran_y)),\n","    cmap=\"cividis\",\n","    marker=\"x\",\n",")\n","\n","# Etiquetas y título del gráfico\n","plt.xlabel(\"Valores reales\")\n","plt.ylabel(\"Predicciones\")\n","plt.title(\"Comparación entre valores reales y predicciones\")\n","plt.xticks(range(26), [chr(65 + i) for i in range(26)])  # Añadir etiquetas de la A a la Z\n","plt.legend()\n","\n","# Mostrar la gráfica\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Apartado 4"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Crear un nuevo DataFrame con las columnas x e y\n","data_embedded = data[y_cols].copy()\n","\n","# Iterar sobre las filas del DataFrame original\n","for index, row in data.iterrows():\n","    # Obtener las columnas de las balizas originales para la fila actual\n","    balizas = row[x_cols]\n","\n","    # Encontrar las dos balizas más cercanas y sus valores\n","    baliza_cercana_1 = balizas.idxmax()\n","    valor_cercano_1 = balizas.max()\n","\n","    # Eliminar la baliza más cercana de las balizas originales y encontrar la segunda baliza más cercana\n","    balizas = balizas.drop(baliza_cercana_1)\n","    baliza_cercana_2 = balizas.idxmax()\n","    valor_cercano_2 = balizas.max()\n","\n","    if valor_cercano_2 == -200:\n","        baliza_cercana_2 = \"Ninguna\"\n","\n","    # Agregar las columnas al nuevo DataFrame\n","    data_embedded.loc[\n","        index,\n","        [\"Baliza_Cercana_1\", \"Valor_Cercano_1\", \"Baliza_Cercana_2\", \"Valor_Cercano_2\"],\n","    ] = [\n","        str(baliza_cercana_1),\n","        float(valor_cercano_1),\n","        str(baliza_cercana_2),\n","        float(valor_cercano_2),\n","    ]\n","\n","# Mostrar el nuevo conjunto de datos\n","print(data_embedded.head(12))"]},{"cell_type":"markdown","metadata":{},"source":["#### Apartado 5\n","Nueva clase"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class EmbeddedBeaconPositioningNN(nn.Module):\n","    embedding: nn.Embedding\n","    layer_1: nn.Linear\n","    layer_2: nn.ReLU\n","    layer_3: nn.Linear\n","    layer_4: nn.ReLU\n","    layer_5: nn.Linear\n","    output: nn.LeakyReLU\n","\n","    def __init__(self):\n","        super().__init__()\n","        self.embedding = self.embedding_layer = nn.Embedding(14, 13)\n","        self.layer_1 = nn.Linear(\n","            in_features=28, out_features=78, bias=True\n","        )  # Idea for number of perceptrons in middle layers: nº of relations between 13 beacons = 13*12/2\n","        self.layer_2 = nn.ReLU()\n","        self.layer_3 = nn.Linear(in_features=78, out_features=78, bias=True)\n","        self.layer_4 = nn.ReLU()\n","        self.layer_5 = nn.Linear(in_features=78, out_features=2, bias=True)\n","        self.output = nn.LeakyReLU()\n","\n","    def forward(self, x, baliza_cercana_1, baliza_cercana_2):\n","        # Paso las balizas cercanas a través de las capas de embedding\n","        embedded_baliza_cercana_1 = self.embedding_layer(baliza_cercana_1).squeeze()\n","        embedded_baliza_cercana_2 = self.embedding_layer(baliza_cercana_2).squeeze()\n","\n","        # Concateno las embeddings con las características originales\n","        x = torch.cat([x, embedded_baliza_cercana_1, embedded_baliza_cercana_2], dim=1)\n","        \n","        # Defino el cálculo del paso forward\n","        x = self.layer_1(x)\n","        x = self.layer_2(x)\n","        x = self.layer_3(x)\n","        x = self.layer_4(x)\n","        x = self.layer_5(x)\n","        x = self.output(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["Resolución"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["baliza_mapping = {baliza: idx for idx, baliza in enumerate(x_cols + [\"Ninguna\"])}\n","\n","X_e = data_embedded[\n","    [\"Baliza_Cercana_1\", \"Valor_Cercano_1\", \"Baliza_Cercana_2\", \"Valor_Cercano_2\"]\n","]\n","Y_e = data_embedded[y_cols]\n","# Dividir datos en conjuntos de entrenamiento y prueba\n","X_train_e, X_test_e, Y_train_e, Y_test_e = train_test_split(\n","    X_e, Y_e, test_size=0.2, random_state=42\n",")\n","\n","# Convertir a tensores de PyTorch\n","X_train_e_num = torch.tensor(\n","    X_train_e[[\"Valor_Cercano_1\", \"Valor_Cercano_2\"]].values, dtype=torch.float32\n",").to(device)\n","Y_train_e = torch.tensor(Y_train_e.values, dtype=torch.float32).to(device)\n","X_test_e_num = torch.tensor(\n","    X_test_e[[\"Valor_Cercano_1\", \"Valor_Cercano_2\"]].values, dtype=torch.float32\n",").to(device)\n","Y_test_e = torch.tensor(Y_test_e.values, dtype=torch.float32).to(device)\n","\n","# Instanciamos la red\n","nnet_e = EmbeddedBeaconPositioningNN()\n","# Copio la red neuronal al dispositivo donde entrene la red neuronal\n","nnet_e = nnet_e.to(device)\n","\n","mapping = vectorize(lambda x: baliza_mapping[x])\n","\n","# Optimizer\n","optimizer_e = torch.optim.Adam(nnet_e.parameters(), lr=0.0001)\n","# cantidad de epochs\n","epochs = 1000\n","\n","# Lista para almacenar el valor medio de pérdida en cada iteración\n","train_loss_values_e = []\n","valid_loss_values_e = []\n","train_mae_values_e = []\n","valid_mae_values_e = []\n","\n","# Doble loop algoritmo Mini-Batch\n","for epoch in range(epochs):\n","    ############################################\n","    ## Entrenamiento\n","    ############################################\n","    nnet_e.train(True)\n","\n","    # Paso forward\n","    # Limpio optimizer para empezar un nuevo cálculo de gradiente\n","    optimizer_e.zero_grad()\n","\n","    train_col_bal_1 = X_train_e[[\"Baliza_Cercana_1\"]].values\n","    train_col_bal_2 = X_train_e[[\"Baliza_Cercana_2\"]].values\n","\n","    train_bal_1 = torch.tensor(mapping(train_col_bal_1), dtype=torch.long).to(device)\n","    train_bal_2 = torch.tensor(mapping(train_col_bal_2), dtype=torch.long).to(device)\n","\n","    train_output = nnet_e(X_train_e_num, train_bal_1, train_bal_2)\n","\n","    # Calculo el loss y mae\n","    train_loss = loss_function(train_output, Y_train_e)\n","    train_mae = mae_function(train_output.cpu().detach(), Y_train_e.cpu().detach())\n","\n","    # Backpropagation\n","    train_loss.backward()\n","\n","    # Actualizar los parámetros\n","    optimizer_e.step()\n","\n","    # Calcular y almacenar el valor medio\n","    train_avg_loss = torch.mean(train_loss).item()\n","    train_loss_values_e.append(train_avg_loss)\n","    train_mae_values_e.append(train_mae)\n","\n","    ############################################\n","    ## Validación\n","    ############################################\n","    # Desactivo el cálculo de gradiente para validación\n","    nnet_e.train(False)\n","\n","    valid_col_bal_1 = X_test_e[[\"Baliza_Cercana_1\"]].values\n","    valid_col_bal_2 = X_test_e[[\"Baliza_Cercana_2\"]].values\n","    valid_bal_1 = torch.tensor(mapping(valid_col_bal_1), dtype=torch.long).to(device)\n","    valid_bal_2 = torch.tensor(mapping(valid_col_bal_2), dtype=torch.long).to(device)\n","\n","    # Paso forward\n","    valid_output = nnet_e(X_test_e_num, valid_bal_1, valid_bal_2)\n","\n","    # Calculo el loss\n","    valid_loss = loss_function(valid_output, Y_test_e)\n","    valid_mae = mae_function(valid_output.cpu().detach(), Y_test_e.cpu().detach())\n","\n","    # En validación no hago backpropagation!!\n","\n","    # Calcular y almacenar el valor medio de pérdida\n","    valid_avg_loss = torch.mean(valid_loss).item()\n","    valid_loss_values_e.append(valid_avg_loss)\n","    valid_mae_values_e.append(valid_mae)\n","\n","############################################\n","## Impresión de resultados por epoch\n","############################################\n","\n","# Crear una figura con dos subgráficos (2 filas, 1 columna)\n","fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n","# Graficar\n","axes[0].plot(train_loss_values, label=\"train\")\n","axes[0].plot(valid_loss_values, label=\"validation\")\n","axes[0].plot(train_loss_values_e, label=\"train(embedded)\")\n","axes[0].plot(valid_loss_values_e, label=\"validation(embedded)\")\n","axes[0].set_xlabel(\"Iteración\")\n","axes[0].set_ylabel(\"Loss\")\n","axes[0].set_title(\"Loss function (MSE) evolution\")\n","axes[0].legend()\n","\n","axes[1].plot(train_mae_values, label=\"train\")\n","axes[1].plot(valid_mae_values, label=\"validation\")\n","axes[1].plot(train_mae_values_e, label=\"train(embedded)\")\n","axes[1].plot(valid_mae_values_e, label=\"validation(embedded)\")\n","axes[1].set_xlabel(\"Iteración\")\n","axes[1].set_ylabel(\"MAE\")\n","axes[1].set_title(\"MAE evolution\")\n","axes[1].legend()\n","\n","# Agregar etiquetas y título\n","fig.suptitle(\"Metricas\")\n","\n","\n","# Mostrar el gráfico\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Apartado 6\n","Tal y como se muestra en las gráficas, se aprecia que la red neuronal con embedding requiere un mayor número de épocas para entrenar. El tiempo de procesamiento tambien es ligeramente mayor que el de la otra red con el modelo de datos que manejamos.\n","\n","La ventaja del modelo con embeddings es que se reduce en gran cantidad la cantidad de datos necesarios, sobre todo si casi nunca se obtiene señal de más de una baliza y en el supuesto de que el número de balizas aumente considerablemente."]}],"metadata":{"colab":{"provenance":[{"file_id":"1RCZzJmmWUgMV6wJt51mOz-vbUh3U4qEC","timestamp":1671758511398},{"file_id":"1xYhggCuBQHNRJM5wq_ywOjINmTuXoenz","timestamp":1669662194271},{"file_id":"1oN3llw9-AGdcGnJsKSE04yIWqruf44Xj","timestamp":1638829440565}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":0}
